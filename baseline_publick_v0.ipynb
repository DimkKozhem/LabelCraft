{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from typing import List, Optional\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((716552, 4), 776, (784742, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_train = pd.read_parquet('labeled_train.parquet')\n",
    "unlabeled_train = pd.read_parquet('unlabeled_train.parquet')\n",
    "categor = pd.read_csv('category_tree.csv')\n",
    "labeled_train.shape, labeled_train['cat_id'].nunique(), unlabeled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_category_tree_path(category_tree):\n",
    "    \"\"\"\n",
    "    Строит дерево категорий, добавляя для каждой категории её цепочку предков.\n",
    "    :param category_tree: Словарь вида {cat_id: parent_id}, где у корневых категорий parent_id = None.\n",
    "    :return: Словарь {cat_id: {\"level\": уровень, \"ancestors\": [предки в порядке от корня до родителя]}}.\n",
    "    \"\"\"\n",
    "    category_info = {}\n",
    "\n",
    "    def get_path_and_level(cat_id):\n",
    "        if cat_id in category_info:\n",
    "            return category_info[cat_id][\"level\"], category_info[cat_id][\"ancestors\"]\n",
    "        parent_id = category_tree.get(cat_id)\n",
    "        if np.isnan(parent_id):\n",
    "            level = 1\n",
    "            ancestors = []\n",
    "        else:\n",
    "            parent_level, parent_ancestors = get_path_and_level(parent_id)\n",
    "            level = parent_level + 1\n",
    "            ancestors = parent_ancestors + [parent_id]\n",
    "        category_info[cat_id] = {\"level\": level, \"ancestors\": ancestors}\n",
    "        return level, ancestors\n",
    "\n",
    "    for cat_id in category_tree:\n",
    "        get_path_and_level(cat_id)\n",
    "\n",
    "    return category_info\n",
    "\n",
    "\n",
    "def find_lowest_common_ancestor(true_id, pred_id, category_info):\n",
    "    \"\"\"\n",
    "    Находит наибольшего общего предка (Lowest Common Ancestor - LCA) между предсказанной \n",
    "    и истинной категорией.\n",
    "    \n",
    "    :param true_id: Истинная категория.\n",
    "    :param pred_id: Предсказанная категория.\n",
    "    :param category_info: Словарь с уровнями категорий.\n",
    "    :return: (LCA, уровень LCA).\n",
    "    \"\"\"\n",
    "    true_info = category_info.get(true_id, {\"level\": 0, \"ancestors\": []})\n",
    "    pred_info = category_info.get(pred_id, {\"level\": 0, \"ancestors\": []})\n",
    "\n",
    "    # Совпадает — нет необходимости искать предка\n",
    "    if true_id == pred_id:\n",
    "        return true_id, true_info[\"level\"]\n",
    "\n",
    "    # Собираем множества предков\n",
    "    true_ancestors = set(true_info[\"ancestors\"] + [true_id])\n",
    "    pred_ancestors = set(pred_info[\"ancestors\"] + [pred_id])\n",
    "\n",
    "    # Ищем наибольшего общего предка\n",
    "    common_ancestors = true_ancestors.intersection(pred_ancestors)\n",
    "    if not common_ancestors:\n",
    "        return None, 0  # Категории не связаны — полный штраф\n",
    "\n",
    "    # Выбираем самого глубокого предка \n",
    "    lca = max(common_ancestors, key=lambda cat: category_info[cat][\"level\"])\n",
    "    \n",
    "    return lca, category_info[lca][\"level\"]\n",
    "\n",
    "\n",
    "def hierarchical_accuracy_with_branch_check(predicted_ids, true_ids, category_tree):\n",
    "    \"\"\"\n",
    "    Рассчитывает метрику, учитывая иерархию категорий и наибольшего общего предка (LCA).\n",
    "\n",
    "    :param predicted_ids: Список предсказанных категорий.\n",
    "    :param true_ids: Список правильных категорий.\n",
    "    :param category_tree: Словарь {cat_id: parent_id}, описывающий иерархию категорий.\n",
    "    :return: Средняя метрика по всем примерам.\n",
    "    \"\"\"\n",
    "    assert len(true_ids) == len(predicted_ids), \"Длина списков не совпадает\"\n",
    "    \n",
    "    # Словарь {cat_id: {\"level\": level, \"ancestors\": ancestors}}\n",
    "    category_info = build_category_tree_path(category_tree)\n",
    "\n",
    "    total_score = 0\n",
    "\n",
    "    for true_id, pred_id in zip(true_ids, predicted_ids):\n",
    "        # Находим LCA для истинного и предсказанного значения\n",
    "        lca, lca_level = find_lowest_common_ancestor(true_id, pred_id, category_info)\n",
    "\n",
    "        if lca is None:\n",
    "            score = 0  # Если совпадений нет, штрафуем по максимуму\n",
    "        else:\n",
    "            true_level = category_info.get(true_id, {\"level\": 0})[\"level\"]\n",
    "            level_difference = max(0, true_level - lca_level)  # LCA сравниваем с истиной\n",
    "            \n",
    "            # Дисконтируем на разницу уровней\n",
    "            score = 1 / math.exp(level_difference)\n",
    "\n",
    "        total_score += score\n",
    "\n",
    "    return total_score / len(true_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((716552, 4), 776, 490)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categor_dict = set(categor.groupby('parent_id')['cat_name'].apply(list).to_dict().keys())\n",
    "category_tree = {}\n",
    "for _, row in categor.iterrows():\n",
    "    cat_id = row['cat_id']\n",
    "    parent_id = row['parent_id']\n",
    "    if pd.isna(parent_id):\n",
    "        parent_id = np.nan  \n",
    "    category_tree[cat_id] = parent_id\n",
    "labeled_train.shape, labeled_train['cat_id'].nunique(), len(categor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "776-418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((716552, 4), 773)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_train['source_name'] = labeled_train['source_name'].str.lower()\n",
    "\n",
    "most_common_cat_id = labeled_train.groupby('source_name')['cat_id'].agg(\n",
    "    lambda x: x.value_counts().index[0] if len(x) > 0 else None\n",
    ").reset_index()\n",
    "most_common_cat_id.rename(columns={'cat_id': 'most_common_cat_id'}, inplace=True)\n",
    "\n",
    "labeled_train = labeled_train.merge(most_common_cat_id, on='source_name', how='left')\n",
    "labeled_train['cat_id'] = labeled_train['most_common_cat_id']\n",
    "\n",
    "labeled_train.drop(columns=['most_common_cat_id'], inplace=True)\n",
    "\n",
    "labeled_train.shape, labeled_train['cat_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train_temp = unlabeled_train.copy()\n",
    "labeled_train_temp = labeled_train.copy()\n",
    "\n",
    "\n",
    "labeled_train_temp['attributes'] = labeled_train_temp['attributes'].str.lower()\n",
    "unlabeled_train_temp['attributes'] = unlabeled_train_temp['attributes'].str.lower()\n",
    "\n",
    "labeled_train_temp = labeled_train_temp.drop_duplicates([\"source_name\"])\n",
    "unlabeled_train_temp = unlabeled_train_temp.drop_duplicates([\"source_name\"])\n",
    "\n",
    "\n",
    "labeled_train_temp = labeled_train_temp[labeled_train_temp['attributes'] != \"[{}]\"]\n",
    "unlabeled_train_temp = unlabeled_train_temp[unlabeled_train_temp['attributes'] != \"[{}]\"]\n",
    "\n",
    "unlabeled_train_temp = unlabeled_train_temp.merge(\n",
    "    labeled_train_temp[['attributes', 'cat_id']], \n",
    "    on='attributes', \n",
    "    how='left'\n",
    ").dropna(subset=['cat_id'])\n",
    "\n",
    "labeled_train = pd.concat([labeled_train, unlabeled_train_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668362, 4), 773)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_train['source_name'] = labeled_train['source_name'].str.lower()\n",
    "most_common_cat_id = labeled_train.groupby('source_name')['cat_id'].agg(lambda x: x.mode().iloc[0]).reset_index()\n",
    "most_common_cat_id.rename(columns={'cat_id': 'most_common_cat_id'}, inplace=True)\n",
    "labeled_train = labeled_train.merge(most_common_cat_id, on='source_name', how='left')\n",
    "labeled_train['cat_id'] = labeled_train['most_common_cat_id']\n",
    "labeled_train.drop(columns=['most_common_cat_id'], inplace=True)\n",
    "labeled_train = labeled_train.drop_duplicates([\"source_name\"])\n",
    "labeled_train.shape, labeled_train['cat_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, (667348,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = labeled_train['cat_id'].value_counts()\n",
    "\n",
    "labeled_train_filtered = labeled_train[labeled_train['cat_id'].isin(class_counts[class_counts > 10].index)]\n",
    "\n",
    "train, test = train_test_split(\n",
    "    labeled_train_filtered, \n",
    "    test_size=0.05, \n",
    "    random_state=42, \n",
    "    stratify=labeled_train_filtered['cat_id']\n",
    ")\n",
    "\n",
    "X_train, y_train = train['source_name'], train['cat_id']\n",
    "X_test, y_test = test['source_name'], test['cat_id']\n",
    "labeled_train_filtered['cat_id'].nunique(), labeled_train_filtered['cat_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=20000,\n",
    "        # min_df=2,\n",
    "        # max_df=0.95,\n",
    "        ngram_range=(1, 3),\n",
    "        sublinear_tf=True,\n",
    "\n",
    "    )),\n",
    "    ('svd', TruncatedSVD(n_components=500))\n",
    "])\n",
    "\n",
    "vectorizer.fit_transform(labeled_train['source_name'])\n",
    "\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха -  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6ce776c469497687bde7312134d157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 HDA: 0.7572\n",
      "Эпоха -  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d6404cb0b9406cb53ad9328e2caebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 HDA: 0.7611\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(\n",
    "    loss='log_loss',         \n",
    "    penalty='l2',            \n",
    "    alpha=0.0001,           \n",
    "    learning_rate='optimal',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "classes = y_train.unique()\n",
    "\n",
    "# Генератор батчей\n",
    "def batch_generator(X, y, batch_size=5000):\n",
    "    for x in tqdm(range(0, len(X), batch_size)):\n",
    "        yield X[x:x+batch_size], y[x:x+batch_size]\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "    print('Эпоха - ', epoch+1)\n",
    "    \n",
    "    indices = np.random.permutation(len(X_train_tfidf))\n",
    "    X_train_shuffled = X_train_tfidf[indices]\n",
    "    y_train_shuffled = y_train.iloc[indices] if hasattr(y_train, 'iloc') else y_train[indices]\n",
    "    \n",
    "    for X_batch, y_batch in batch_generator(X_train_shuffled, y_train_shuffled, batch_size=5000):\n",
    "        clf.partial_fit(X_batch, y_batch, classes=classes)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    hda = hierarchical_accuracy_with_branch_check(y_pred, y_test, category_tree)\n",
    "    print(f\"Epoch {epoch+1} HDA: {hda:.4f}\")\n",
    "\n",
    "\n",
    "with open(\"baseline_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "with open(\"baseline_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
